"""
AkÄ±llÄ± Kariyer AsistanÄ± - Ana Uygulama (BÃ–L VE FETHET STRATEJÄ°SÄ°)
Bu dosya, tÃ¼m sistem bileÅŸenlerini koordine eder ve uygulamanÄ±n giriÅŸ noktasÄ±dÄ±r.
"""

import os
import sys
import pandas as pd
from dotenv import load_dotenv

# Environment variables yÃ¼kle
load_dotenv()

# ModÃ¼lleri import et
from src.data_collector import collect_job_data
from src.cv_processor import CVProcessor
from src.embedding_service import EmbeddingService
from src.vector_store import VectorStore
from src.filter import filter_junior_suitable_jobs, filter_jobs_by_date

# KonfigÃ¼rasyon sabitleri
ENABLE_DATE_FILTER = True  # Manuel doÄŸrulama iÃ§in True yapÄ±n
DATE_FILTER_DAYS = 3       # Son X gÃ¼n iÃ§indeki ilanlar
MIN_SIMILARITY_THRESHOLD = 50  # Benzerlik eÅŸiÄŸi (%) - Daha fazla sonuÃ§ iÃ§in dÃ¼ÅŸÃ¼rÃ¼ldÃ¼

def collect_data_for_all_personas():
    """
    TÃ¼m personalar iÃ§in ayrÄ± ayrÄ± veri toplar ve sonuÃ§larÄ± birleÅŸtirir.
    BÃ–L VE FETHET stratejisi: KarmaÅŸÄ±k bir sorgu yerine basit sorgular
    """
    print("\nğŸ” Stratejik Veri Toplama BaÅŸlatÄ±lÄ±yor (BÃ¶l ve Fethet - Ã‡oklu Site)...")
    print("=" * 60)

    # Her bir persona iÃ§in basit ve etkili arama terimleri
    persona_search_terms = {
        "Yazilim_Gelistirici": "YazÄ±lÄ±m GeliÅŸtirici",
        "Full_Stack": "Full Stack Developer",
        "React_Developer": "React Developer",
        "Python_Developer": "Python Developer",
        "Analist": "Ä°ÅŸ Analisti",
        "Veri_Analisti": "Veri Analisti",
        "Business_Analyst": "Business Analyst",
        "ERP_Danismani": "ERP DanÄ±ÅŸmanÄ±",
        "ERP_Specialist": "ERP Specialist",
        "Proses_Gelistirme": "SÃ¼reÃ§ GeliÅŸtirme",
        "Flutter_Developer": "Flutter Developer",
        "TypeScript_Developer": "TypeScript"
    }

    all_jobs_list = []
    total_collected = 0

    for persona, term in persona_search_terms.items():
        print(f"\n--- Persona '{persona}' iÃ§in arama yapÄ±lÄ±yor ---")
        print(f"ğŸ” Arama terimi: '{term}'")

        try:
            # Her persona iÃ§in Ã§oklu site aramasÄ± (DataFrame dÃ¶ndÃ¼rÃ¼r)
            jobs_df = collect_job_data(search_term=term, max_results_per_site=20)

            if jobs_df is not None and not jobs_df.empty:
                print(f"âœ… {len(jobs_df)} ilan toplandÄ±")                # Persona bilgisini ekle
                jobs_df['persona'] = persona
                jobs_df['search_term'] = term
                all_jobs_list.append(jobs_df)
                total_collected += len(jobs_df)
            else:
                print(f"âŒ '{term}' iÃ§in ilan bulunamadÄ±")

        except Exception as e:
            print(f"âŒ '{term}' iÃ§in hata: {str(e)}")
            continue

    if not all_jobs_list:
        print("âŒ HiÃ§bir persona iÃ§in ilan bulunamadÄ±. Genel bir sorun olabilir.")
        return None

    # TÃ¼m DataFrame'leri birleÅŸtir
    print(f"\nğŸ”„ {len(all_jobs_list)} persona sonucu birleÅŸtiriliyor...")
    final_df = pd.concat(all_jobs_list, ignore_index=True)

    print(f"ğŸ“Š BirleÅŸtirme Ã¶ncesi: {len(final_df)} ilan")    # Tekrarlanan ilanlarÄ± kaldÄ±r (ÅŸirket + baÅŸlÄ±k + lokasyon bazÄ±nda)
    final_df.drop_duplicates(subset=['company', 'title', 'location'], inplace=True)

    print(f"âœ¨ Tekrar temizleme sonrasÄ±: {len(final_df)} benzersiz ilan")

    # NOT: Tarih filtresi burada deÄŸil, AI analizi sÄ±rasÄ±nda date_posted field'Ä± Ã¼zerinden yapÄ±lacak
    # Ã‡Ã¼nkÃ¼ JobSpy'Ä±n date_posted formatÄ±: "1 day ago", "3 days ago" ÅŸeklinde

    # BirleÅŸtirilmiÅŸ veriyi tek bir dosyaya kaydet
    output_dir = "data"
    os.makedirs(output_dir, exist_ok=True)
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    final_csv_path = os.path.join(output_dir, f"birlesmis_ilanlar_{timestamp}.csv")
    final_df.to_csv(final_csv_path, index=False, encoding='utf-8')

    print(f"ğŸ“ TÃ¼m veriler ÅŸuraya kaydedildi: {final_csv_path}")
    print(f"ğŸ¯ Toplam baÅŸarÄ±: {len(final_df)} benzersiz ilan!")

    return final_csv_path

def analyze_and_find_best_jobs():
    """Tam otomatik analiz: Stratejik veri toplama + AI analizi + SonuÃ§lar"""
    print("\nğŸš€ Tam Otomatik AI Kariyer Analizi BaÅŸlatÄ±lÄ±yor...")
    print("=" * 60)

    # 1. BÃ–L VE FETHET ile fresh data toplayalÄ±m
    print("ğŸ”„ 1/6: Stratejik veri toplama...")
    csv_path = collect_data_for_all_personas()  # YENÄ° FONKSÄ°YONU Ã‡AÄIRIYORUZ
    if not csv_path:
        print("âŒ Veri toplama baÅŸarÄ±sÄ±z - analiz durduruluyor!")
        return

    # 2. CV'yi iÅŸle
    print("\nğŸ“„ 2/6: CV analizi...")
    cv_processor = CVProcessor()
    if not cv_processor.load_cv():
        print("âŒ CV yÃ¼kleme baÅŸarÄ±sÄ±z!")
        return

    if not cv_processor.create_cv_embedding():
        print("âŒ CV embedding oluÅŸturma baÅŸarÄ±sÄ±z!")
        return

    cv_embedding = cv_processor.cv_embedding
    print("âœ… CV embedding oluÅŸturuldu")

    # 3. Vector store'u baÅŸlat
    print("\nğŸ—ƒï¸ 3/6: Vector store hazÄ±rlÄ±ÄŸÄ±...")
    vector_store = VectorStore()

    # 4. Ä°ÅŸ ilanlarÄ±nÄ± vector store'a yÃ¼kle
    print("ğŸ”„ 4/6: Ä°ÅŸ ilanlarÄ± vector store'a yÃ¼kleniyor...")

    # CSV'yi oku
    jobs_df = pd.read_csv(csv_path)
    print(f"ğŸ“Š {len(jobs_df)} iÅŸ ilanÄ± yÃ¼klendi")

    # Koleksiyon oluÅŸtur
    if not vector_store.create_collection():
        print("âŒ Vector store koleksiyon oluÅŸturma baÅŸarÄ±sÄ±z!")
        return

    # Ä°ÅŸ ilanlarÄ± iÃ§in embeddings oluÅŸtur
    embedding_service = EmbeddingService()

    print("ğŸ”„ 5/6: Ä°ÅŸ ilanlarÄ± iÃ§in AI embeddings oluÅŸturuluyor...")
    job_embeddings = []
    for _, job in jobs_df.iterrows():
        if pd.notna(job.get('description', '')):
            embedding = embedding_service.create_embedding(str(job['description']))
            job_embeddings.append(embedding)
        else:
            job_embeddings.append(None)

    # Vector store'a ekle
    success = vector_store.add_jobs(jobs_df, job_embeddings)
    if not success:
        print("âŒ Vector store yÃ¼kleme baÅŸarÄ±sÄ±z!")
        return

    print("âœ… Vector store hazÄ±r")    # 5. Benzer iÅŸleri bul ve filtrele
    print("\nğŸ”„ 6/6: AkÄ±llÄ± eÅŸleÅŸtirme ve filtreleme...")
    similar_jobs = vector_store.search_similar_jobs(cv_embedding, top_k=30)  # Daha fazla al

    if similar_jobs:
        # ADIM 1: Tarih filtresi (manuel doÄŸrulama ile aynÄ± zaman penceresi)
        if ENABLE_DATE_FILTER:
            print(f"ğŸ“… Tarih filtresi uygulanÄ±yor (son {DATE_FILTER_DAYS} gÃ¼n)...")
            similar_jobs = filter_jobs_by_date(similar_jobs, max_days=DATE_FILTER_DAYS, debug=False)
            print(f"ğŸ“Š Tarih filtresi sonrasÄ±: {len(similar_jobs)} ilan")
          # ADIM 2: YBS odaklÄ± detaylÄ± filtreleme
        print("ğŸ” SonuÃ§lar YBS/junior pozisyonlar iÃ§in akÄ±llÄ± filtreleme...")
        filtered_jobs = filter_junior_suitable_jobs(similar_jobs, debug=False)

        if filtered_jobs:
            # ADIM 3: Uygunluk puanÄ± eÅŸiÄŸi ekleme (Strateji 3)
            high_quality_jobs = [job for job in filtered_jobs if job['similarity_score'] >= MIN_SIMILARITY_THRESHOLD]

            if high_quality_jobs:
                print(f"âœ… {len(high_quality_jobs)} adet yÃ¼ksek kaliteli pozisyon bulundu!")
                print(f"ğŸ“Š Uygunluk eÅŸiÄŸi: %{MIN_SIMILARITY_THRESHOLD} ve Ã¼zeri")

                print("\n" + "="*70)
                print("ğŸ‰ SÄ°ZE Ã–ZEL EN UYGUN Ä°Å Ä°LANLARI")
                print("ğŸ¯ YBS + Full-Stack + Veri Analizi OdaklÄ±")
                print("="*70)

                for i, job in enumerate(high_quality_jobs[:15], 1):  # Top 15 gÃ¶ster
                    print(f"\n{i}. {job['title']} - {job['company']}")
                    print(f"   ğŸ“ {job['location']}")
                    print(f"   ğŸ“Š Uygunluk: %{job['similarity_score']:.1f}")
                    if 'persona' in job:
                        print(f"   ğŸ­ Persona: {job['persona']}")
                    print(f"   ğŸ”— {job['url']}")
                    print("-" * 50)

                print(f"\nğŸ¯ Analiz tamamlandÄ±! {len(high_quality_jobs)} yÃ¼ksek kaliteli pozisyon listelendi.")

                # Persona daÄŸÄ±lÄ±mÄ± analizi
                if high_quality_jobs and 'persona' in high_quality_jobs[0]:
                    persona_counts = {}
                    for job in high_quality_jobs:
                        persona = job.get('persona', 'Unknown')
                        persona_counts[persona] = persona_counts.get(persona, 0) + 1

                    print(f"\nğŸ“ˆ Persona DaÄŸÄ±lÄ±mÄ±:")
                    for persona, count in sorted(persona_counts.items(), key=lambda x: x[1], reverse=True):
                        print(f"   {persona}: {count} ilan")

            else:
                print(f"âš ï¸  Filtreleme sonrasÄ± {len(filtered_jobs)} ilan bulundu ama uygunluk eÅŸiÄŸi (%{MIN_SIMILARITY_THRESHOLD}) altÄ±nda.")
                print("ğŸ’¡ EÅŸiÄŸi dÃ¼ÅŸÃ¼rmeyi veya persona terimlerini geniÅŸletmeyi dÃ¼ÅŸÃ¼nebilirsiniz.")

        else:
            print("âŒ Filtreleme sonrasÄ± uygun pozisyon bulunamadÄ±! Kriterleri gÃ¶zden geÃ§irin.")
    else:
        print("âŒ Benzer iÅŸ bulunamadÄ±!")

def print_manual_validation_guide():
    """Manuel doÄŸrulama protokolÃ¼ rehberini yazdÄ±rÄ±r"""
    print("\n" + "="*80)
    print("ğŸ“‹ MANUEL DOÄRULAMA PROTOKOLÃœ REHBERÄ°")
    print("ğŸ”¬ Sistemin 'kÃ¶r noktalarÄ±nÄ±' tespit etmek iÃ§in adÄ±m adÄ±m rehber")
    print("="*80)

    print(f"""
ğŸ”¹ ADIM 1: Manuel Arama (Indeed'de)
   â€¢ Indeed.com'da giriÅŸ yapÄ±n
   â€¢ Filtreler: 'Son {DATE_FILTER_DAYS} gÃ¼n', 'TÃ¼rkiye', 'Entry Level/Junior'
   â€¢ Arama terimleri (sÄ±rayla deneyin):
     - "YazÄ±lÄ±m GeliÅŸtirici"
     - "Full Stack Developer"
     - "Ä°ÅŸ Analisti"
     - "ERP DanÄ±ÅŸmanÄ±"
   â€¢ 2-3 tane "mÃ¼kemmel uyum" ilan tespit edin ve kaydedin

ğŸ”¹ ADIM 2: Sistem Ã‡alÄ±ÅŸtÄ±rma
   â€¢ Bu scripti Ã§alÄ±ÅŸtÄ±rÄ±n (ENABLE_DATE_FILTER=True olduÄŸundan emin olun)
   â€¢ Sistem otomatik olarak son {DATE_FILTER_DAYS} gÃ¼nlÃ¼k ilanlarÄ± filtreleyecek
   â€¢ SonuÃ§lar gÃ¶rÃ¼ntÃ¼lendiÄŸinde manuel bulduÄŸunuz ilanlarÄ± kontrol edin

ğŸ”¹ ADIM 3: KarÅŸÄ±laÅŸtÄ±rma Analizi
   â€¢ Manuel bulduÄŸunuz "mÃ¼kemmel uyum" ilanlar sistem sonuÃ§larÄ±nda var mÄ±?
   â€¢ VARSA: âœ… Sistem Ã§alÄ±ÅŸÄ±yor, kÃ¶r nokta yok
   â€¢ YOKSA: âŒ KÃ–R NOKTA TESPÄ°T EDÄ°LDÄ°!

ğŸ”¹ ADIM 4: KÃ¶r Nokta DÃ¼zeltme (eÄŸer varsa)
   â€¢ KaÃ§Ä±rÄ±lan ilanlarÄ±n arama terimlerini analiz edin
   â€¢ persona_search_terms listesine yeni terimler ekleyin
   â€¢ Filtreleme kriterlerini gÃ¶zden geÃ§irin
   â€¢ Tekrar test edin

ğŸ”¹ ADIM 5: SÃ¼rekli Ä°yileÅŸtirme
   â€¢ Bu protokolÃ¼ haftalÄ±k Ã§alÄ±ÅŸtÄ±rÄ±n
   â€¢ Yeni iÅŸ trendlerini yakalayÄ±n
   â€¢ Sistem performansÄ±nÄ± takip edin

ğŸ’¡ NOT: Bu protokol bilimsel doÄŸrulamanÄ±n temelini oluÅŸturur!
""")

    print("="*80)
    print(f"ğŸ¯ SÄ°STEM DURUMU: Tarih filtresi {'AÃ‡IK' if ENABLE_DATE_FILTER else 'KAPALI'} (â‰¤{DATE_FILTER_DAYS} gÃ¼n)")
    print("="*80)

def main():
    """Tek komutla tam otomatik AI kariyer analizi"""
    print("ğŸš€ AkÄ±llÄ± Kariyer AsistanÄ± - BÃ¶l ve Fethet Stratejisi")
    print("=" * 60)

    # Manuel doÄŸrulama rehberini gÃ¶ster
    print_manual_validation_guide()

    # Ã–n kontroller
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key or api_key == "your_gemini_api_key_here":
        print("âŒ HATA: Gemini API key bulunamadÄ±!")
        print("ğŸ“ LÃ¼tfen .env dosyasÄ±nda GEMINI_API_KEY deÄŸerini ayarlayÄ±n.")
        return

    cv_path = "data/cv.txt"
    if not os.path.exists(cv_path):
        print(f"âŒ HATA: CV dosyasÄ± bulunamadÄ±: {cv_path}")
        print("ğŸ“ LÃ¼tfen CV'nizi data/cv.txt dosyasÄ±na ekleyin.")
        return

    print("âœ… Sistem kontrolleri baÅŸarÄ±lÄ±")
    print("ğŸ¯ 12 farklÄ± persona ile stratejik veri toplama baÅŸlatÄ±lÄ±yor...\n")

    # Tam otomatik analiz Ã§alÄ±ÅŸtÄ±r
    analyze_and_find_best_jobs()


# Test fonksiyonlarÄ± iÃ§in
if __name__ == "__main__":
    main()
