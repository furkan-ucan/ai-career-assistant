"""
AkÄ±llÄ± Kariyer AsistanÄ± - Ana Uygulama (BÃ–L VE FETHET STRATEJÄ°SÄ°)
Bu dosya, tÃ¼m sistem bileÅŸenlerini koordine eder ve uygulamanÄ±n giriÅŸ noktasÄ±dÄ±r.
"""

# Standard Library
import logging
import os
from datetime import datetime
from pathlib import Path

# Third Party
import pandas as pd
import yaml
from dotenv import load_dotenv
from tqdm import tqdm

# Local
from src.cv_processor import CVProcessor
from src.data_collector import collect_job_data
from src.embedding_service import EmbeddingService
from src.filter import score_jobs
from src.intelligent_scoring import IntelligentScoringSystem
from src.vector_store import VectorStore

# Environment variables yÃ¼kle
load_dotenv()

# Loglama konfigÃ¼rasyonu
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


def load_config():
    """config.yaml dosyasÄ±nÄ± yÃ¼kle"""
    config_path = Path("config.yaml")
    try:
        with open(config_path, "r", encoding="utf-8") as file:
            config = yaml.safe_load(file)
        logger.info("âœ… config.yaml baÅŸarÄ±yla yÃ¼klendi")
        return config
    except FileNotFoundError:
        logger.error(f"âŒ config.yaml dosyasÄ± bulunamadÄ±: {config_path}")
        raise
    except yaml.YAMLError as e:
        logger.error(f"âŒ config.yaml dosyasÄ± parse edilemedi: {e}")
        raise


# KonfigÃ¼rasyonu yÃ¼kle
config = load_config()
scoring_system = IntelligentScoringSystem(config)

# KonfigÃ¼rasyondan ayarlarÄ± al
job_settings = config["job_search_settings"]
MIN_SIMILARITY_THRESHOLD = job_settings["min_similarity_threshold"]
HEDEFLENEN_SITELER = job_settings["target_sites"]
DEFAULT_HOURS_OLD = job_settings["default_hours_old"]
DEFAULT_RESULTS_PER_PERSONA_SITE = job_settings["default_results_per_site"]

# Persona konfigÃ¼rasyonlarÄ±
persona_search_config = config["persona_search_configs"]


def collect_data_for_all_personas():
    """
    JobSpy GeliÅŸmiÅŸ Ã–zellikler ile TÃ¼m Personalar iÃ§in Optimize EdilmiÅŸ Veri Toplama
    Config.yaml'dan persona ayarlarÄ± alÄ±nÄ±r.
    """
    logger.info("ğŸ” JobSpy GeliÅŸmiÅŸ Ã–zellikler ile Stratejik Veri Toplama BaÅŸlatÄ±lÄ±yor...")
    logger.info("=" * 70)

    all_collected_jobs_list = []

    for persona_name, persona_cfg in tqdm(persona_search_config.items(), desc="Persona AramalarÄ±"):
        logger.info(f"\n--- Persona '{persona_name}' iÃ§in JobSpy GeliÅŸmiÅŸ Arama ---")
        logger.info(f"ğŸ¯ Optimize edilmiÅŸ terim: '{persona_cfg['term']}'")
        logger.info(f"â° Tarih filtresi: Son {persona_cfg['hours_old']} saat")

        try:
            # JobSpy'Ä±n geliÅŸmiÅŸ Ã¶zelliklerini kullanarak veri toplama
            jobs_df_for_persona = collect_job_data(
                search_term=persona_cfg["term"],
                site_names=HEDEFLENEN_SITELER,  # LinkedIn + Indeed
                location="Turkey",
                max_results_per_site=persona_cfg["results"],
                hours_old=persona_cfg["hours_old"],
            )
            if jobs_df_for_persona is not None and not jobs_df_for_persona.empty:
                # Persona bilgisini ve arama terimini ekle (analiz iÃ§in faydalÄ±)
                jobs_df_for_persona["persona_source"] = persona_name
                jobs_df_for_persona["search_term_used"] = persona_cfg["term"]
                all_collected_jobs_list.append(jobs_df_for_persona)
                logger.info(f"âœ¨ Persona '{persona_name}' iÃ§in {len(jobs_df_for_persona)} ilan bulundu.")
            else:
                logger.info(f"â„¹ï¸ Persona '{persona_name}' iÃ§in hiÃ§bir siteden ilan bulunamadÄ±.")

        except Exception as e:
            logger.error(f"âŒ Persona '{persona_name}' iÃ§in hata: {str(e)}", exc_info=True)
            continue

    if not all_collected_jobs_list:
        logger.error("âŒ HiÃ§bir persona ve site kombinasyonundan ilan bulunamadÄ±.")
        return None  # TÃ¼m personalarÄ±n sonuÃ§larÄ±nÄ± birleÅŸtir
    final_df = pd.concat(all_collected_jobs_list, ignore_index=True)
    logger.info(f"\nğŸ“Š BirleÅŸtirme Ã¶ncesi (tÃ¼m personalar): {len(final_df)} ilan")

    # Son genel deduplication (persona'lar arasÄ± tekrarlar iÃ§in)
    if "description" in final_df.columns and not final_df.empty:
        final_df["description_short"] = final_df["description"].astype(str).str[:100]
        final_df.drop_duplicates(
            subset=["title", "company", "location", "description_short"], inplace=True, keep="first"
        )
        final_df.drop(columns=["description_short"], inplace=True)
    elif not final_df.empty:
        final_df.drop_duplicates(subset=["title", "company", "location"], inplace=True, keep="first")

    logger.info(f"âœ¨âœ¨âœ¨ TOPLAM: {len(final_df)} adet BENZERSÄ°Z ilan (JobSpy optimize edilmiÅŸ)! âœ¨âœ¨âœ¨")

    # Optimize edilmiÅŸ CSV kaydetme (pathlib ile)
    output_dir = Path(config["paths"]["data_dir"])
    output_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    final_csv_path = output_dir / f"jobspy_optimize_ilanlar_{timestamp}.csv"
    final_df.to_csv(final_csv_path, index=False, encoding="utf-8")
    logger.info(f"ğŸ“ JobSpy optimize edilmiÅŸ veriler: {final_csv_path}")

    return str(final_csv_path)


def analyze_and_find_best_jobs():
    """Tam otomatik analiz: Stratejik veri toplama + AI analizi + SonuÃ§lar"""
    logger.info("\nğŸš€ Tam Otomatik AI Kariyer Analizi BaÅŸlatÄ±lÄ±yor...")
    logger.info("=" * 60)

    # 1. Veri toplama
    logger.info("\nğŸ”„ 1/6: JobSpy GeliÅŸmiÅŸ Ã–zellikler ile veri toplama...")
    csv_path = collect_data_for_all_personas()
    if not csv_path:
        logger.error("âŒ Veri toplama baÅŸarÄ±sÄ±z - analiz durduruluyor!")
        return

    # 2. CV'yi iÅŸle
    logger.info("\nğŸ“„ 2/6: CV analizi...")
    cv_processor = CVProcessor()
    if not cv_processor.load_cv():
        logger.error("âŒ CV yÃ¼kleme baÅŸarÄ±sÄ±z!")
        return

    if not cv_processor.create_cv_embedding():
        logger.error("âŒ CV embedding oluÅŸturma baÅŸarÄ±sÄ±z!")
        return

    cv_embedding = cv_processor.cv_embedding
    logger.info("âœ… CV embedding oluÅŸturuldu")

    # 3. Vector store'u baÅŸlat
    logger.info("\nğŸ—ƒï¸ 3/6: Vector store hazÄ±rlÄ±ÄŸÄ±...")
    vector_store = VectorStore()

    # 4. Ä°ÅŸ ilanlarÄ±nÄ± vector store'a yÃ¼kle
    logger.info("ğŸ”„ 4/6: Ä°ÅŸ ilanlarÄ± vector store'a yÃ¼kleniyor...")  # CSV'yi pathlib ile oku
    try:
        csv_path_obj = Path(csv_path)
        jobs_df = pd.read_csv(csv_path_obj)
        logger.info(f"ğŸ“Š {len(jobs_df)} iÅŸ ilanÄ± yÃ¼klendi")
    except FileNotFoundError:
        logger.error(f"âŒ CSV dosyasÄ± bulunamadÄ±: {csv_path}")
        return
    except pd.errors.EmptyDataError:
        logger.error("âŒ CSV dosyasÄ± boÅŸ!")
        return
    except Exception as e:
        logger.error(f"âŒ CSV okuma hatasÄ±: {e}")
        return

    # Koleksiyon oluÅŸtur
    if not vector_store.create_collection():
        logger.error("âŒ Vector store koleksiyon oluÅŸturma baÅŸarÄ±sÄ±z!")
        return

    # Ä°ÅŸ ilanlarÄ± iÃ§in embeddings oluÅŸtur (tqdm ile)
    embedding_service = EmbeddingService()

    logger.info("ğŸ”„ 5/6: Ä°ÅŸ ilanlarÄ± iÃ§in AI embeddings oluÅŸturuluyor...")
    job_embeddings = []

    for _, job in tqdm(jobs_df.iterrows(), total=len(jobs_df), desc="Ä°lan Embeddings"):
        if pd.notna(job.get("description", "")):
            try:
                embedding = embedding_service.create_embedding(str(job["description"]))
                job_embeddings.append(embedding)
            except Exception as e:
                logger.warning(f"âš ï¸ Embedding oluÅŸturma hatasÄ±: {e}")
                job_embeddings.append(None)
        else:
            job_embeddings.append(None)  # Vector store'a ekle (deduplication ile)
    success = vector_store.add_jobs(jobs_df, job_embeddings)
    if not success:
        logger.error("âŒ Vector store yÃ¼kleme baÅŸarÄ±sÄ±z!")
        return

    # 5. Benzer iÅŸleri bul ve filtrele
    logger.info("\nğŸ”„ 6/6: AkÄ±llÄ± eÅŸleÅŸtirme ve filtreleme...")
    # Vector store aramasÄ±
    search_results = vector_store.search_jobs(cv_embedding, n_results=50)
    similar_jobs = [
        dict(metadata, similarity_score=(1 - dist) * 100)
        for metadata, dist in zip(search_results.get("metadatas", []), search_results.get("distances", []))
    ]

    if similar_jobs:
        logger.info("ğŸ” SonuÃ§lar akÄ±llÄ± puanlama ile deÄŸerlendiriliyor...")
        scored_jobs = score_jobs(similar_jobs, scoring_system, debug=False)
        high_quality_jobs = [job for job in scored_jobs if job["similarity_score"] >= MIN_SIMILARITY_THRESHOLD]

        if high_quality_jobs:
            logger.info(f"âœ… {len(high_quality_jobs)} adet yÃ¼ksek kaliteli pozisyon bulundu!")
            logger.info(f"ğŸ“Š Uygunluk eÅŸiÄŸi: %{MIN_SIMILARITY_THRESHOLD} ve Ã¼zeri")
            logger.info("\n" + "=" * 70)
            logger.info("ğŸ‰ SÄ°ZE Ã–ZEL EN UYGUN Ä°Å Ä°LANLARI (JobSpy Optimize)")
            logger.info("ğŸ¯ YBS + Full-Stack + Veri Analizi OdaklÄ±")
            logger.info("=" * 70)

            for i, job in enumerate(high_quality_jobs[:15], 1):  # Top 15 gÃ¶ster
                logger.info(f"\n{i}. {job['title']} - {job['company']}")
                logger.info(f"   ğŸ“ {job['location']}")
                logger.info(f"   ğŸ“Š Uygunluk: %{job['similarity_score']:.1f}")
                logger.info(f"   ğŸ’¼ Site: {job.get('source_site', 'N/A')}")
                logger.info(f"   ğŸ‘¤ Persona: {job.get('persona_source', job.get('persona', 'N/A'))}")
                logger.info(f"   ğŸ”— {job.get('url', 'URL bulunamadÄ±')}")
                logger.info("-" * 50)

            logger.info(f"\nğŸ¯ Analiz tamamlandÄ±! {len(high_quality_jobs)} yÃ¼ksek kaliteli pozisyon listelendi.")

            if high_quality_jobs and ("persona_source" in high_quality_jobs[0] or "persona" in high_quality_jobs[0]):
                persona_counts = {}
                for job in high_quality_jobs:
                    persona = job.get("persona_source", job.get("persona", "Unknown"))
                    persona_counts[persona] = persona_counts.get(persona, 0) + 1

                logger.info("\nğŸ“ˆ Persona DaÄŸÄ±lÄ±mÄ±:")
                for persona, count in sorted(persona_counts.items(), key=lambda x: x[1], reverse=True):
                    logger.info(f"   {persona}: {count} ilan")

        else:
            logger.warning(
                f"âš ï¸  {len(scored_jobs)} ilan bulundu ancak uygunluk eÅŸiÄŸi (%{MIN_SIMILARITY_THRESHOLD}) altÄ±nda."
            )
            logger.info("ğŸ’¡ EÅŸiÄŸi dÃ¼ÅŸÃ¼rmeyi veya persona terimlerini geniÅŸletmeyi dÃ¼ÅŸÃ¼nebilirsiniz.")
    else:
        logger.warning("âŒ Benzer iÅŸ bulunamadÄ±!")


def print_manual_validation_guide():
    """JobSpy GeliÅŸmiÅŸ Ã–zellikler iÃ§in Manuel DoÄŸrulama ProtokolÃ¼"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‹ JOBSPY GELÄ°ÅMÄ°Å Ã–ZELLÄ°KLER - MANUEL DOÄRULAMA PROTOKOLÃœ")
    logger.info("=" * 80)
    logger.info("ğŸ¯ SÄ°STEM DURUMU: JobSpy Native (hours_old=72, cosine similarity)")
    logger.info("ğŸš€ Optimize Ã–zellikler: Ã‡oklu site, geliÅŸmiÅŸ operatÃ¶rler, 12 persona")
    logger.info("ğŸ“Š Beklenen Performans: 100-300 benzersiz ilan, %80+ uygunluk oranÄ±")
    logger.info("=" * 80)


def main():
    """Tek komutla tam otomatik AI kariyer analizi"""
    logger.info("ğŸš€ AkÄ±llÄ± Kariyer AsistanÄ± - BÃ¶l ve Fethet Stratejisi")
    logger.info("=" * 60)

    # Manuel doÄŸrulama rehberini gÃ¶ster
    print_manual_validation_guide()  # Ã–n kontroller
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key or api_key == "your_gemini_api_key_here":
        logger.error("âŒ HATA: Gemini API key bulunamadÄ±!")
        logger.info("ğŸ“ LÃ¼tfen .env dosyasÄ±nda GEMINI_API_KEY deÄŸerini ayarlayÄ±n.")
        return

    # pathlib kullanarak CV dosyasÄ± kontrol
    cv_path = Path(config["paths"]["cv_file"])
    try:
        if not cv_path.exists():
            logger.error(f"âŒ HATA: CV dosyasÄ± bulunamadÄ±: {cv_path}")
            logger.info("ğŸ“ LÃ¼tfen CV'nizi data/cv.txt dosyasÄ±na ekleyin.")
            return

        # CV dosyasÄ±nÄ±n okunabilir olduÄŸunu kontrol et
        if cv_path.stat().st_size == 0:
            logger.error(f"âŒ HATA: CV dosyasÄ± boÅŸ: {cv_path}")
            return

    except (OSError, IOError) as e:
        logger.error(f"âŒ HATA: CV dosyasÄ± eriÅŸim hatasÄ±: {e}")
        return

    logger.info("âœ… Sistem kontrolleri baÅŸarÄ±lÄ±")
    logger.info("ğŸ¯ 12 farklÄ± JobSpy optimize edilmiÅŸ persona ile veri toplama baÅŸlatÄ±lÄ±yor...\n")

    # Tam otomatik analiz Ã§alÄ±ÅŸtÄ±r
    analyze_and_find_best_jobs()


# Test fonksiyonlarÄ± iÃ§in
if __name__ == "__main__":
    main()
